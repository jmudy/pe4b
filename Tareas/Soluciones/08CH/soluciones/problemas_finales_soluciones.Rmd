---
title: "Taller problemas finales"
author: ""
date: ""
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    df_print: paged
    toc: yes
  word_document:
    toc: yes
linkcolor: red
header-includes: \renewcommand{\contentsname}{Contenidos}
citecolor: blue
toccolor: blue
urlcolor: blue
---





```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,cache=TRUE)
library(tidyverse)
options(scipen=999)
contador=0
cuenta=function(x=contador) {contador<<- contador+1;return(contador)}
set.seed(2020)
```


# Taller final SOLUCIONES

Se trata de resolver los siguientes problemas y cuestiones en un fichero Rmd y su  salida en un informe en  html, word  o pdf.



## Problema `r cuenta()`: Contraste de parámetros de dos muestras.

Queremos comparar los tiempos de realización de un test entre
estudiantes de dos grados G1 y G2, y determinar si es verdad
que los estudiantes de G1 emplean menos tiempo que los de
G2. No conocemos $\sigma_1$ y $\sigma_2$.
Disponemos de dos muestras independientes de cuestionarios
realizados por estudiantes de cada grado, $n_1=n_2=50$.

Los datos están en https://github.com/joanby/estadistica-inferencial/, en la carpeta `datasets` en dos ficheros `grado1.txt` y `grado2.txt`.

Para bajarlos utilizad la dirección del los ficheros `raw`  que se muestran en el siguiente código


```{r cargadatosoculta}
G1=read.csv(
  "https://raw.githubusercontent.com/joanby/estadistica-inferencial/master/datasets/grado1.txt",
            header=TRUE)$x
G2=read.csv(
  "https://raw.githubusercontent.com/joanby/estadistica-inferencial/master/datasets/grado2.txt",
  header=TRUE)$x

n1=length(na.omit(G1))
n2=length(na.omit(G2))
media.muestra1=mean(G1,na.rm=TRUE)
media.muestra2=mean(G2,na.rm=TRUE)
desv.tip.muestra1=sd(G1,na.rm=TRUE)
desv.tip.muestra2=sd(G2,na.rm=TRUE)
```

Calculamos las medias y las desviaciones típicas muestrales de los tiempos empleados para cada muestra. Los datos obtenidos se resumen en la siguiente tabla:


$$
\begin{array}{llll}
n_1&=`r n1`, & n_2&=`r n2`\\
\overline{x}_1&=`r media.muestra1`, & \overline{x}_2&=`r media.muestra2`\\
\tilde{s}_1&=`r desv.tip.muestra1`, & \tilde{s}_2&=`r desv.tip.muestra2`
\end{array}
$$
Se pide:

1. Comentad brevemente el código de R explicando que hace cada instrucción.
2. Contrastad si hay evidencia de que las notas medias son distintas entre los dos grupos. En dos casos considerando las varianzas desconocidas pero iguales o desconocidas pero distintas. Tenéis que hacer el contraste de forma manual y con funciones de  `R` y resolver el contrate con el $p$-valor. 
3. Calculad e interpretar los intervalos de confianza para la diferencia de medias asociados a  los dos test anteriores. 
4. Comprobad con el test de Fisher. Tenéis que resolver el test de Fisher con `R` o   de forma manual  con ayudados para los $p$-valores con alguan hoja de cálculo. Decidir utilizando el $p$-valor. 




### Solución


**Apartado 1.** El cogido R carga en las variables G1 y G2 la variables `x` de dos data frames de un servidor  en github y por lo tanto hemos tenido que pasar la url del fichero original o  *raw*.

Luego calcula los estadísticos básicos para  realizar las siguientes preguntas. Para los tamaños muestrales $n_1$ y $n_2$  se omiten los valores `NA` antes de asignar la `length` de los arrays. También se calculan las medias y las desviaciones típicas muestrales omitiendo (si es que hay)  los valores no disponibles.

**Apartado 2.**
Denotemos por $\mu_1$ y $\mu_2$ las medias de las notas de los grupos 1 y 2 respectivamente. El contraste que se pide  es


$$
\left\{\begin{array}{ll}
H_0:\mu_{1} = \mu_{2}\\
H_1: \mu_{1} \not= \mu_{2}
\end{array}\right.
$$



Estamos en un diseño de comparación de medias de dos grupos con dos muestras  independientes de tamaño 50 que es grande. Tenemos dos casos varianzas desconocidas pero iguales y varianzas desconocidas pero distintas. Las funciones de R del contraste  para estos casos son:



**Varianzas iguales**

```{r}
# test para varianzas iguales
t.test(G1,G2,var.equal = TRUE,alternative = "two.sided")

```
**Varianzas distintas**

```{r}
# test para varianzas distintas
t.test(G1,G2,var.equal = FALSE,alternative = "two.sided")
```

El $p$-valor en ambos casos es muy pequeño así que la muestra  no aporta evidencias rechazar la hipótesis nula las medias son iguales contra que son distintas.



Veamos el cálculo manual.


**Varianzas desconocidas pero iguales, $n_1$ y $n_2$ grande** 

Si suponemos que $\sigma_1=\sigma_2$, el estadístico de contraste es
$$
t0=\frac{\overline{X}_1-\overline{X}_2}
{\sqrt{(\frac1{n_1}+\frac1{n_2})\cdot 
\frac{((n_1-1)\widetilde{S}_1^2+(n_2-1)\widetilde{S}_2^2)}
{(n_1+n_2-2)}}}=\frac{`r media.muestra1`-`r media.muestra2`}
{\sqrt{(\frac1{`r n1`}+\frac1{`r n2`})\cdot 
\frac{((`r n1`-1) `r desv.tip.muestra1`^2+(`r n2`-1)`r desv.tip.muestra2`^2)}
{(`r n1`+`r n2`-2)}}}
$$

```{r estadisticos_ejer1}
t0=(media.muestra1-media.muestra2)/sqrt((1/n1+1/n2)* 
((n1-1) *desv.tip.muestra1^2+(n2-1)*desv.tip.muestra2^2)/(n1+n2-2))
t0
```


operando obtenemos que  $t0=`r round(t0,6)`.$ y sabemos que  sigue una distribución  $t$-Student $t_{n_1+n_2-2}=t_{`r n1+n2-2`}$. Para este hipótesis alternativa el $p$-valor es 

$2\cdot P(t_{`r n1+n2-2`}>|`r t0`|)$, lo calculamos con R 


```{r estadisticos_ejercico1_2}
t0=(media.muestra1-media.muestra2)/sqrt((1/n1+1/n2)* 
((n1-1) *desv.tip.muestra1^2+(n2-1)*desv.tip.muestra2^2)/(n1+n2-2))
t0
n1
n2
2*(1-pt(abs(t0),df=n1+n2-2)) # calculo la probabilidad del complementario
2*pt(abs(t0),df=n1+n2-2,lower.tail = FALSE)# calcula el área la cola  superior

```


**Varianzas desconocidas pero distintas, $n_1$ y $n_2$ grande**

Si suponemos que $\sigma_1\neq \sigma_2$, el estadístico de contraste es
$t0=\frac{\overline{X}_1-\overline{X}_2}{\sqrt{\frac{\widetilde{S}_1^2}{n_1}+\frac{\widetilde{S}_2^2}{n_2}}}\sim t_f,$
que, cuando $\mu_1=\mu_2$, tiene distribución (aproximadamente, en caso de muestras grandes) $t_{f}$ con
$$
f=\frac{\displaystyle \left( \frac{\widetilde{S}_1^2}{n_1}+\frac{\widetilde{S}_2^2}{n_2}\right)^2}
{\displaystyle \frac1{n_1-1}\left(\frac{\widetilde{S}_1^2}{n_1}\right)^2+\frac1{n_2-1}\left(\frac{\widetilde{S}_2^2}{n_2}\right)^2}.
$$

Calculamos el estadístico  y los grados de libertad con R

```{r}
t0=(media.muestra1-media.muestra2)/sqrt(desv.tip.muestra1^2/n1+desv.tip.muestra2^2/n2)
#calculo el valor dentro del floor que es el que utiliza la función t.test de R para este caso.
t0

f=(desv.tip.muestra1^2/n1+desv.tip.muestra2^2/n2)^2/(
  (1/(n1-1))*(desv.tip.muestra1^2/n1)^2+(1/(n2-1))*(desv.tip.muestra2^2/n2)^2)
f

```

El $p$ valor es 


```{r}
# el p-valor de la función t.test de  R
2*(pt(abs(t0),f,lower.tail = FALSE))
```



**Apartado 3**

Los intervalos de confianza al nivel del 95% los podemos obtener así


```{r}
t.test(G1,G2,var.equal = TRUE,alternative = "two.sided",conf.level = 0.95)$conf.int
t.test(G1,G2,var.equal = FALSE,alternative = "two.sided",conf.level = 0.95)$conf.int
```


Son similares, podemos asegurar que   la diferencia de medias se encuentra $-2.25<\mu_1-\mu_2< -1.16$ al nivel del 95 el grupo 2 tiene una media entre 2.25 y 1.16 puntos mayor que el grupo 2 aproximadamente.


**Apartado 4**
El test que nos piden es el de igualdad de varianzas



$$\left\{\begin{array}{ll}H_0: & \sigma_1^2=\sigma_2^2\\
H_1: & \sigma_1^2\not=\sigma_2^2\end{array}\right..$$



El test de Fisher de igualdad de varianzas

```{r}
var.test(G1,G2,alternative ="two.sided" )
```

Obtenemos un $p$-valor alto no podemos rechazar la igualdad de varianzas.


De forma manual el estadístico de este test sabemos que es 


$$f_0=\frac{\tilde{S_1}^2}{\tilde{S_2}^2}=\frac{`r desv.tip.muestra1^2`}{`r desv.tip.muestra2^2`}=`r desv.tip.muestra1^2/desv.tip.muestra2^2`.$$

Que sigue una ley de distribución de  Fisher
y el $p$_valor es $\min\{2\cdot P(F_{n_1-1,+n_2-1}\leq f_0),2\cdot P(F_{n_1-1,+n_2-1}\geq f_0).$

que con R es 


```{r}
n1
n2
f0=desv.tip.muestra1^2/desv.tip.muestra2^2
f0
pvalor=min(2*pf(f0,n1-1,n2-2),2*pf(f0,n1-1,n2-2,lower.tail = FALSE))
pvalor
```


Obtenemos los mismos resultados que con la función `var.test`.



El test de Levene con R tiene las mismas hipótesis que el anterior

```{r levene1,warning=FALSE}
library(car,quietly = TRUE)# pongo quietly para que quite avisos
notas=c(G1,G2)
grupo=as.factor(c(rep(1,length(G1)),rep(2,length(G1))))
leveneTest(notas~grupo)
```

El $p$-valor obtenido es alto así que el test de Levene no aporta evidencias contra la igualdad de varianzas entre las notas de los dos grupos.



## Problema `r cuenta()` : Contraste dos muestras

Simulamos dos muestras con las funciones siguientes 


```{r generacionmuestras100}
set.seed(2020)
x1=rnorm(100,mean = 10,sd=2)
x2=rnorm(100,mean = 8,sd=4)
```
Dibujamos estos gráficos

```{r}
boxplot(x1,x2)
library(car)
par(mfrow=c(1,2))
qqPlot(x1)
qqPlot(x2)
par(mfrow=c(1,1))
```

Realizamos algunos contrastes de hipótesis de igual de medias entre ambas muestras

```{r test_t_muestras}
t.test(x1,x2,var.equal = TRUE,alternative = "greater")
t.test(x1,x2,var.equal = FALSE,alternative = "two.sided")
t.test(x1,x2,var.equal = TRUE)
```

Se pide

1. ¿Cuál es la distribución  y los parámetros de las muestras generadas? 
2. ¿Qué muestran y cuál es  la interpretación de los gráficos? 
3. ¿Qué test contrasta si hay evidencia a favor de que las medias poblacionales de las notas en cada grupo sean distintas? Di qué código de los anteriores resuelve este test. 
4. Para el test del apartado anterior dad las hipótesis nula y alternativa y redactar la conclusión del contraste.



### Solución

**Apartado 1**

Se generan dos muestras de poblaciones normales  de medias 10 y 8 y desviaciones típicas 2 y 4.
 
**Apartado 2**
El primer gráficos es un diagrama de caja (*boxplot*) que compara   las distribuciones de los datos. Vemos que efectivamente la muestra 1 tiene una caja y unos bigotes más comprimidos que la muestra 2  así que la primera tiene menos varianza.  Vemos que los valores medianos  de la muestra 1 son más grandes que los de la muestra 2. Recordemos que la distribución normal es simétrica por lo que la media y la mediana coinciden. La muestra 1 tiene valores atípicos en la parte superior 1 y en la inferior parece que 2.

El segundo gráfico es un gráfico cuantil-cuantil o qqplot de normalidad. Compara los cuantiles muestrales con los teóricos  de una normal y nos da un intervalo de confianza para esas observaciones.

Vemos que los cuantiles teóricos no difieren excesivamente de los muestrales en cada una de las muestras y que muy pocos valores se escapan de los intervalos de confianza esperados en el caso de normalidad. 
Así que no hay motivo para pensar que las distribuciones de ambas muestras proceden de poblaciones normales.


**Apartado 3**

El código es 

```
t.test(x1,x2,var.equal = TRUE,alternative = "greater")
t.test(x1,x2,var.equal = FALSE,alternative = "two.sided")
t.test(x1,x2,var.equal = TRUE)
```


El primer test contrasta para muestras independientes supuestas varianzas desconocidas pero iguales $H_0;\mu_1=\mu_2$ contra $H_1:\mu_1>\mu_2$. **Así que este TEST NO ES**


El segundo test contrasta para muestras independientes supuestas varianzas  desconocidas pero iguales $H_0;\mu_1=\mu_2$ contra $H_1:\mu_1\not=\mu_2$. **Así que este TEST SÍ PUEDE SER**  contrasta contra medias distintas para el caso de varianzas distintas.


El tercer test contrasta para muestras independientes supuestas varianzas  desconocidas pero iguales $H_0;\mu_1=\mu_2$ contra $H_1:\mu_1>\mu_2$ pues la opción por defecto de la función. **Así que este TEST SÍ PUEDE SER**   contra medias distintas para el caso de varianzas iguales.




**Apartado 4**
El contrastes es 

$$\left\{\begin{array}{ll}H_0: & \mu_1=\mu_2\\ H_1: & \mu_1\not=\mu_2\end{array}\right.
$$


En los dos últimos test los $p$-valores son muy muy pequeños así que hay evidencias en contra de la igualdad de medias entre las dos muestras.  Además claramente los intervalos de confianza no contienen al cero.





## Problema `r cuenta()` : ANOVA Comparación de las tasas de interés  para la compra de coches  entre seis ciudades.

Consideremos el  `data set` `newcar` accesible desde https://www.itl.nist.gov/div898/education/anova/newcar.dat de *Hoaglin, D., Mosteller, F., and Tukey, J. (1991). Fundamentals of Exploratory Analysis of Variance. Wiley, New York, page 71.* 

Este data set contiene dos columnas:

* Rate (interés): tasa de interés en la compra de coches a crédito 
* City (ciudad) : la ciudad en la que se observó la tasa de interés para distintos concesionarios (codificada a enteros). Tenemos observaciones de  6 ciudades. 

```{r}
datos_interes=read.table(
  "https://www.itl.nist.gov/div898/education/anova/newcar.dat",
  skip=25)
# salto las 25 primeras líneas del fichero,son un preámbulo que explica los datos.
names(datos_interes)=c("interes","ciudad")
str(datos_interes)
boxplot(interes~ciudad,data=datos_interes)
```

Se pide:

1. Comentad el código y  el diagrama de caja.
2. Se trata de contrastar si hay evidencia de  que  la tasas medias de interés por ciudades son distintas. Definid el ANOVA que contrasta esta hipótesis y especificar qué condiciones deben cumplir las muestras para poder aplicar el ANOVA.  
3. Comprobad las condiciones del ANOVA  con un test KS y un test de Levene (con código de `R`).  Justificad las conclusiones.  
4. Realizad el contraste de ANOVA (se cumplan las condiciones o no) y redactar adecuadamente la conclusión. Tenéis que hacedlo con  funciones de `R`.  
5. Se acepte o no la igualdad de medias realizar las comparaciones dos a dos con ajustando los $p$-valor tanto por  Bonferroni como por Holm al nivel de significación $\alpha=0.1$. Redactad las conclusiones que se obtienen de las mismas.  


### Solución

**Apartado 1**

El código del enunciado nos carga los datos de una web, tenemos que pasar el parámetro skip=25 para que se salte las 25 primeras lineas del fichero de texto  que son un preámbulo que explica los datos.

En el diagrama de caja vemos que las medias las distribuciones de la `Rate` por ciudad son muy distintas, no parecen tener ni medias ni varianzas iguales


**Apartado 2**

Las condiciones para realizar un ANOVA son:

* Muestras independientes y aleatorias 
* Distribución normal de la Rate $N(\mu_i,\sigma_i)$ para las seis ciudades $i=1,2,3,4,5,6$.
* homocedasticidad; igualdad de varianzas $\sigma_1=\sigma_2=\sigma_3
=\sigma_4=\sigma_5=\sigma_6.$



El ANOVA que se pide  es  

$$
\left\{
\begin{array}{ll}
H_0: &  \mu_1=\mu_2=\mu_3=\mu_4=\mu_5=\mu_6\\
H_1: & \mbox{ no  todas las medias son iguales}.
\end{array}
\right.
$$


**Apartado 3**

El siguiente código realiza un test KS con corrección de Lillie para la normalidad de la variable Rate en cada una  de la seis ciudades 

```{r}
library(nortest)
lillie.test(datos_interes$interes[datos_interes$ciudad==1])
lillie.test(datos_interes$interes[datos_interes$ciudad==2])
lillie.test(datos_interes$interes[datos_interes$ciudad==3])
lillie.test(datos_interes$interes[datos_interes$ciudad==4])
lillie.test(datos_interes$interes[datos_interes$ciudad==5])
lillie.test(datos_interes$interes[datos_interes$ciudad==6])
```

No podemos rechazar la normalidad con el lillie.test en las 5 primeras ciudades, pero parece que la última está lejos de ser normal.


Ahora  comprobemos que 

$$
\left\{
\begin{array}{ll}
H_0: &  \sigma^2_1=\sigma^2_2=\sigma^2_3=\sigma^2_4=\sigma^2_5=\sigma^2_6\\
H_1: & \mbox{ no  todas las varianzas son iguales}.
\end{array}
\right.
$$

con el test de Levene (o el de Bartlett)

```{r}
library(car)
print(leveneTest(datos_interes$interes~as.factor(datos_interes$ciudad)))
```
El test de levene nos da un $p$-valor superior a 0.28 aceptamos la igualdad de varianzas

**Apartado 4**

Resolvemos el ANOVA con el código siguiente

```{r}
summary(aov(datos_interes$interes~as.factor(datos_interes$ciudad)))
```

El $p$-valor es muy bajo 0.00117 rechazamos la igualdad de las seis medias, al menos hay dos distintas.

Comprobamos por gusto el $p$-valor a partir de  los datos del summary

```{r}
Fest=2.1891/0.4533
Fest
1-pf(Fest,5,48)
pf(Fest,5,48,lower.tail = FALSE)
```


**Apartado 5**

Comparemos las medias dos a dos son 15 comparaciones


```{r}
pairwise.t.test(datos_interes$interes,as.factor(datos_interes$ciudad),p.adjust.method = "holm")
```


Nos piden que decidamos con $\alpha=0.1$, así que rechazaremos la igualdad de medias de todas las comparaciones con $p$-valor inferior a $0.1$.

Tenemos que rechazar la igualdad de medias entre la  ciudad  2 con la 5  y la de la ciudad 6 con las ciudades 1, 3, 4 y 5.









## Problema `r cuenta()`: Cuestiones cortas

* Cuestión 1: Supongamos que conocemos el $p$-valor de un contraste. Para que valores de nivel de significación $\alpha$ RECHAZAMOS la hipótesis nula.
* Cuestión 2: Hemos realizado un ANOVA de un factor con 3 niveles, y hemos obtenido un $p$-valor de 0.001. Suponiendo que las poblaciones satisfacen las condiciones para que el ANOVA tenga sentido, ¿podemos afirmar con un nivel de significación $\alpha= 0.05$ que las medias de los tres niveles son diferentes dos a dos? Justificad la respuesta.



### Solución

**Cuestion 1**: Rechazamos la hipótesis nula para todos los niveles de significación $\alpha$ menores que el $p$-valor.

**Cuestion 2**:  No, no podemos afirmar eso. Lo que sabemos después de rechazar un ANOVA es que hay al menos dos medias distintas.




## Problema `r cuenta()`: Contraste de proporciones de dos muestras independientes.

Queremos comparar las proporciones de aciertos de dos redes neuronales que detectan tipos si una foto con un móvil de una avispa es una [avispa velutina o asiática](https://es.wikipedia.org/wiki/Vespa_velutina). Esta avispa en una especie invasora y peligrosa por el veneno de su picadura.
Para ello disponemos de una muestra de 1000 imágenes de insectos etiquetadas como avispa velutina y no velutina.

Em el github del curso os tenéis que descargar de la carpeta de datos los dicheros "algoritmo1.csv" y "algoritmo2.csv". Cada uno está en fichero los aciertos están codificados  con 1 y los fallos con 0.


Se pide:

1. Cargad los datos los datos y calcular el tamaño de las muestras y la proporción de aciertos de cada muestra.
2. Contrastad si hay evidencia de que las las proporciones de aciertos del algoritmo 1  son mayores que las del algoritmo 2. Definid bien las hipótesis y las condiciones del contraste. Tenéis que hacer el contraste con funciones de  `R` y resolver el contrate con el $p$-valor.
3. Calculad e interpretar los intervalos de confianza para la diferencia de proporciones asociados al test anterior, con funciones de R. 




### Solución


```{r}
algoritmo1=read.table("../../../Datos/algoritmo1.csv")
algoritmo2=read.table("../../../Datos/algoritmo1.csv")
```


Proporción aciertos de cada algoritmo

```{r}
n1=dim(algoritmo1)[1]
n1
n1=length(algoritmo1$V1)
n1
n2=length(algoritmo2$V1)
n2
aciertos_absolutos_algoritmo1=table(algoritmo1)["1"]
aciertos_absolutos_algoritmo1
p1=prop.table(table(algoritmo1))["1"]
p1

aciertos_absolutos_algoritmo2=table(algoritmo2)["1"]
aciertos_absolutos_algoritmo2
p2=prop.table(table(algoritmo2))["1"]
p2
```

Después de los cálculos preliminares  si denotamos las proporciones poblacionales de aciertos de cada algoritmo por $p_1$  y $p_2$ respectivamente,  el  contraste que nos piden es  


$$
\left\{
\begin{array}{ll}
H_0: & p_1=p_2\\
H_1: & p_1>p_2\\
\end{array}
\right.
$$


estamos ante un diseño de comparación de proporciones con muestras independientes. Con R lo podemos resolver con el `fisher.test` o con el `prop.test`

```{r}
x=matrix(c(aciertos_absolutos_algoritmo1,n1-aciertos_absolutos_algoritmo1,
           aciertos_absolutos_algoritmo2,n2-aciertos_absolutos_algoritmo2),
         ncol=2,byrow=FALSE)
x
fisher.test(x,alternative="greater",conf.level=0.95)
```



```{r}
c(aciertos_absolutos_algoritmo1,aciertos_absolutos_algoritmo2)
c(n1,n2)
prop.test(c(aciertos_absolutos_algoritmo1,aciertos_absolutos_algoritmo2), c(n1,n2),alternative="greater",conf.level=0.95)
```


Con ambos test obtenemos $p$ valores altos (el más pequeño es el de Fisher y es mayor que $0.4$, así que no podemos rechazar  que las proporciones de aciertos de los dos algoritmos sean  iguales contra que la proporción de aciertos del algoritmo 1 es mejor  que la del 2.


El intervalo  de confianza asociado a este test  es 

```{r}
prop.test(c(aciertos_absolutos_algoritmo1,aciertos_absolutos_algoritmo2), c(n1,n2),alternative="greater",conf.level=0.95)$conf.int
```


luego con una probabilidad del 95\% la $p_1-p_2> -1$  contiene el 0 y no podemos despreciar que sean iguales contra que $p_1>p_2.$

